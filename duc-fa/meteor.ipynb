{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNC4NqfzuBuUzqgL9nffg46"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#<div dir=rtl>\n","<h1> <b>توضیحات</b></h1>\n","</div>"],"metadata":{"id":"3uyRvgG30EQB"}},{"cell_type":"markdown","source":["<div dir=rtl>\n","معیار ارزیابی ترجمه با ترتیب صریح، معیاری است که برای رسیدگی به محدودیت‌های BLEU، که یک معیار ارزیابی رایج برای ترجمه ماشینی است، طراحی شده است. BLEU بر تطابق n گرم متکی است، جایی که تعداد n-گرم های همپوشانی بین ترجمه تولید شده توسط ماشین و ترجمه مرجع را می شمارد. با این حال، این رویکرد دارای چندین کاستی است. به عنوان مثال، BLEU ریشه و مترادف کلمات را در نظر نمی گیرد، به این معنی که با \"running\" مطابقت ندارد.\n","و \"اجرا می کند\"، زیرا آنها به عنوان یک کلمه در فرآیند تطبیق n-gram محاسبه نمی شوند. علاوه بر این، BLEU از recall استفاده نمی کند، که منجر به جریمه شدن جملات کوتاه می شودبرای غلبه بر این محدودیت ها، METEOR از یک امتیاز F وزنی و یک تابع جریمه استفاده می کند که برای در نظر گرفتن دقت و یادآوری اصلاح شده است. الگوریتم با تراز کردن فرضیه و مرجع برای یافتن طولانی ترین تکه کلمه منطبق شروع می شود. در طول این فرآیند هم‌ترازی، مترادف‌ها (معمولاً از یک لغت نامه یا یک مجموعه خارجی بزرگ به دست می‌آیند) در نظر گرفته می‌شوند تا کلماتی با معنی یکسان به عنوان یک کلمه در نظر گرفته شوند. این کمک می کند تا انواع مورفولوژیکی و سایر تفاوت های ظریف که در غیر این صورت هنگام مقایسه ترجمه های مختلف از بین می روند، در نظر گرفته شوند. سپس دقت (P)precision و recall (R) بر اساس تعداد تک‌گرم‌های منطبق محاسبه می‌شوند، جایی که یونی‌گرم‌ها تک کلمات هستند. امتیاز F به عنوان میانگین هارمونیک precision و recall  محاسبه می شود:.\n","\n","$precision = \\frac{matched unigrams}{unigram in hypothesis}$\n","\n","$recall = \\frac{matched unigrams}{unigram in refrences}$\n","\n","$Fscore = \\frac{10 ⋅ precision ⋅ recall}{recall + 9 ⋅ precision}$\n","\n","\n","سپس، متریک تابع پنالتی را محاسبه می‌کنیم، که هدف آن کاهش تأثیر جملات کوتاه پیوسته و در نتیجه پاداش دادن به جملات پیوسته طولانی‌تر است. تعداد تکه‌ها، که گروه‌های پیوسته از کلمات منطبق هستند، برای جریمه کردن جملات کوتاه و پاداش دادن به منطبقات طولانی‌تر محدود شده است. در نهایت، METEOR به عنوان امتیاز F محاسبه می شود\n","ضرب در (1-پنالتی):\n","\n","\n","\n","$Penalty = {0.5} \\times \\frac{number-of-chunk}{matched-unigrams}$\n","\n","$METEOR = F SCORE \\times (1 − Penalty)$\n","\n","\n","\n","یکی از مزایای کلیدی METEOR نسبت به BLEU این است که ریشه و مترادف کلمات را در نظر می گیرد و همچنین عطف کلمات را از طریق تراز کردن در نظر می گیرد. این بدان معنی است که METEOR بهتر می تواند شباهت معنایی بین ترجمه تولید شده توسط ماشین و ترجمه مرجع را که ارزیابی آن در BLEU دشوار است، به دست آورد. علاوه بر این، METEOR مشکلات جریمه BLEU جملات کوتاه را با ترکیب توابع recall امتیاز F و پنالتی کاهش می دهد. مطالعات تجربی نشان داده است که METEOR با قضاوت انسان همبستگی بالاتری نسبت به BLEU در جمله دارد.\n","\n","\n","حالا این اتفاقات را در کد بیشتر بررسی میکنیم\n","</div>\n","\n","\n","---\n","\n","\n","<div dir=rtl>\n","در این بخش با استفاده از nltk از تابع پیدا کردن ریشه استفاده کرده که از پایگاه داده بزرگی استفاده میکند\n","</div>\n","\n","```\n","class meteor:\n","\tdef __init__(self):\n","\t\tself.stemmer = PorterStemmer()\n","```\n","\n","\n","<div dir=rtl>\n","این متریک توانایی دارد جمله ترجمه توسط ماشین را با چند جمله مرجع بسنجد و امتیاز جمله مرجعی که بیشترین تطبیق را با ترجمه توسط ماشین برگرداند.\n","</div>\n","\n","```\n","\tdef metor_score(self, refs, pred):\n","\t\treturn max([self._metor_single_refs_pred(ref, pred) for ref in refs])\n","```\n","<div dir=rtl>\n","self._create_num برای اینکه بتوانیم پیوستگی جملات را بررسی کنیم\n","</div>\n","\n","\n","\n","```\n","\tdef _metor_single_refs_pred(self, ref, pred):\n","\t\tref_num_word = self._create_num(ref)\n","\t\tpred_num_word = self._create_num(pred)\n","\n","```\n","\n","\n","<div dir=rtl>\n","self._create_num :\n","\n","\n","\n","کوچک کردن حروف  \n","توکن کردن\n","</div>\n","\n","\n","\n","```\n","\tdef _create_num(self, text):\n","\t\ttext = text.lower()\n","\t\twords = text.split()\n","\t\tnum_words = [tuple([index, words[index]]) for index in range(len(words))]\n","\t\treturn num_words\n","\n","```\n","\n","\n","<div dir=rtl>\n","یک مثال را از ویکی پدیا انتخاب کرده و با ان پیش میرویم :‌\n","\n","[wikipedia](https://en.wikipedia.org/wiki/METEOR)\n","</div>\n","\n","\n"],"metadata":{"id":"9iCHoyMYnYgU"}},{"cell_type":"code","source":["def _create_num(text):\n","  text = text.lower()\n","  words = text.split()\n","  num_words = [tuple([index, words[index]]) for index in range(len(words))]\n","  return num_words"],"metadata":{"id":"JxVG8d5yBqvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ref = \"the cat sat on the mat\"\n","pred = \"the cat was sat on the mat\"\n","ref_num_word = _create_num(ref)\n","pred_num_word = _create_num(pred)\n","f\"ref  : {ref_num_word} , pred : {pred_num_word}\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"WXHJlsdUF_9v","executionInfo":{"status":"ok","timestamp":1691991302253,"user_tz":-210,"elapsed":80,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"622ce211-d99e-49d4-f01e-28c5df46c399"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"ref  : [(0, 'the'), (1, 'cat'), (2, 'sat'), (3, 'on'), (4, 'the'), (5, 'mat')] , pred : [(0, 'the'), (1, 'cat'), (2, 'was'), (3, 'sat'), (4, 'on'), (5, 'the'), (6, 'mat')]\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["<div dir=rtl>\n","در مرحله بعد کماتی که عینا در ترجمه ماشینی و جمله مرجع هستند را پیدا کرده و از جمله حذف کرده\n","</div>\n","\n","\n","\n","```\n","\t\tmatching_word_by_word , ref_num_word , pred_num_word = self._matching_word_by_word(ref_num_word, pred_num_word)\n","\n","```\n","\n","\n","\n","\n","\n","```\n","\tdef _matching_word_by_word(self, ref_num_word, pred_num_word):\n","\t\tmatching_word_by_word = list()\n","\t\tfor index_pred in range(0 , len(pred_num_word))[::-1]:\n","\t\t\tfor index_ref in range(0, len(ref_num_word))[::-1]:\n","\t\t\t\tif pred_num_word[index_pred][1] == ref_num_word[index_ref][1]:\n","\t\t\t\t\tmatching_word_by_word.append(tuple([pred_num_word[index_pred][0], ref_num_word[index_ref][0]]))\n","\t\t\t\t\tref_num_word.pop(index_ref)\n","\t\t\t\t\tpred_num_word.pop(index_pred)\n","\t\t\t\t\tbreak\n","\t\treturn matching_word_by_word , ref_num_word, pred_num_word\n","```\n","\n","\n","\n"],"metadata":{"id":"CrT6DYQ5ms53"}},{"cell_type":"code","source":["def _matching_word_by_word(ref_num_word, pred_num_word):\n","\tmatching_word_by_word = list()\n","\tfor index_pred in range(0 , len(pred_num_word))[::-1]:\n","\t\tfor index_ref in range(0, len(ref_num_word))[::-1]:\n","\t\t\tif pred_num_word[index_pred][1] == ref_num_word[index_ref][1]:\n","\t\t\t\tmatching_word_by_word.append(tuple([pred_num_word[index_pred][0], ref_num_word[index_ref][0]]))\n","\t\t\t\tref_num_word.pop(index_ref)\n","\t\t\t\tpred_num_word.pop(index_pred)\n","\t\t\t\tbreak\n","\treturn matching_word_by_word , ref_num_word, pred_num_word"],"metadata":{"id":"xWBaaTwzmmsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matching_word_by_word , ref_num_word , pred_num_word = _matching_word_by_word(ref_num_word, pred_num_word)"],"metadata":{"id":"mKvM3Qz-naMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ref_num_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQvMxkQtnjkK","executionInfo":{"status":"ok","timestamp":1691991302256,"user_tz":-210,"elapsed":72,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"0c86e70a-07cf-441e-d20b-0507e2a5027b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["pred_num_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6dZktpJnkZi","executionInfo":{"status":"ok","timestamp":1691991302258,"user_tz":-210,"elapsed":63,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"b5354172-2cbc-40d2-d904-4cf2215b5a86"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(2, 'was')]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["matching_word_by_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a5BdFZLnmrk","executionInfo":{"status":"ok","timestamp":1691991302259,"user_tz":-210,"elapsed":57,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"39587628-49e7-42f0-9bc6-9e5e5713f34f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(6, 5), (5, 4), (4, 3), (3, 2), (1, 1), (0, 0)]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["<div dir=rtl>\n","در مرحله بعدی با استفاده از ریشه یابی کلمات مشترک را پیدا کرده\n","</div>\n","\n","\n","```\n","\t\tstemmer_matching_word_by_word , ref_num_word , pred_num_word = self._stemmer_matching_word_by_word(ref_num_word, pred_num_word)\n","\n","```\n","\n","\n","\n","```\n","\n","\tdef _stemmer_matching_word_by_word(self, ref_num_word, pred_num_word):\n","\t\tref_num_word = [tuple([element[0], self.stemmer.stem(element[1])]) for element in ref_num_word]\n","\t\tpred_num_word = [tuple([element[0], self.stemmer.stem(element[1])]) for element in pred_num_word]\n","\t\treturn self._matching_word_by_word(ref_num_word, pred_num_word)\n","```\n","\n","\n","\n"],"metadata":{"id":"_5iRW69No0Q_"}},{"cell_type":"code","source":["from nltk.stem.api import StemmerI\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n","\n","def _stemmer_matching_word_by_word(ref_num_word, pred_num_word):\n","  ref_num_word = [tuple([element[0], stemmer.stem(element[1])]) for element in ref_num_word]\n","  pred_num_word = [tuple([element[0], stemmer.stem(element[1])]) for element in pred_num_word]\n","  return _matching_word_by_word(ref_num_word, pred_num_word)"],"metadata":{"id":"Ojcx24BIoq7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stemmer_matching_word_by_word , ref_num_word , pred_num_word = _stemmer_matching_word_by_word(ref_num_word, pred_num_word)"],"metadata":{"id":"d1t6SL6xpfa8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ref_num_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8mtMTj7qD-L","executionInfo":{"status":"ok","timestamp":1691991302263,"user_tz":-210,"elapsed":53,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"6fbda3fb-9287-4e4c-b911-efe7827d8ff6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["pred_num_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oE879b6RqGzx","executionInfo":{"status":"ok","timestamp":1691991302264,"user_tz":-210,"elapsed":48,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"a7843871-4927-48ae-e9d6-6d9bb8dffa3a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(2, 'wa')]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["stemmer_matching_word_by_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDpkdj5jqIBC","executionInfo":{"status":"ok","timestamp":1691991302265,"user_tz":-210,"elapsed":44,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"92255bd9-1e7b-4255-cb05-755cc55ee282"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["<div dir=rtl>\n","حالا با استفاده از لم کلمات کلمات مشابه را پیدا کرده\n","</div>\n","\n","\n","\n","```\n","\t\tsynonymm_matching_word_by_word , ref_num_word , pred_num_word = self._synonymm_matching_word_by_word(ref_num_word, pred_num_word)\n","\n","```\n","\n","\n","\n","```\n","\tdef _synonymm_matching_word_by_word(self, ref_num_word, pred_num_word):\n","\t\tmatching_word_by_word = []\n","\t\tfor index_pred in range(0, len(pred_num_word))[::-1]:\n","\t\t\tword_synonymms= wordnet.synsets(pred_num_word[index_pred][1])\n","\t\t\tpred_synonymm = [pred_num_word[index_pred][1]]\n","\n","\t\t\tfor synonymm in word_synonymms:\n","\t\t\t\tfor lemma in synonymm.lemmas():\n","\t\t\t\t\tif lemma.name().find(\"_\") < 0:\n","\t\t\t\t\t\tpred_synonymm.append(lemma.name())\n","\n","\t\t\tpred_synonymm = set(pred_synonymm)\n","\n","\t\t\tfor index_ref in range(0, len(ref_num_word))[::-1]:\n","\t\t\t\tif ref_num_word[index_ref] in pred_synonymm:\n","\t\t\t\t\tmatching_word_by_word.append(tuple([pred_num_word[index_pred][0], ref_num_word[index_ref][0]]))\n","\t\t\t\t\tref_num_word.pop(index_ref)\n","\t\t\t\t\tpred_num_word.pop(index_pred)\n","\t\t\t\t\tbreak\n","\t\treturn matching_word_by_word, ref_num_word, pred_num_word\n","```\n","\n","\n","\n"],"metadata":{"id":"dvaMinj9rMUr"}},{"cell_type":"code","source":["\n","import nltk\n","nltk.download('wordnet')\n","from nltk.corpus import WordNetCorpusReader, wordnet\n","\n","def _synonymm_matching_word_by_word(ref_num_word, pred_num_word):\n","  matching_word_by_word = []\n","  for index_pred in range(0, len(pred_num_word))[::-1]:\n","    word_synonymms= wordnet.synsets(pred_num_word[index_pred][1])\n","    pred_synonymm = [pred_num_word[index_pred][1]]\n","\n","    for synonymm in word_synonymms:\n","      for lemma in synonymm.lemmas():\n","        if lemma.name().find(\"_\") < 0:\n","          pred_synonymm.append(lemma.name())\n","\n","    pred_synonymm = set(pred_synonymm)\n","\n","    for index_ref in range(0, len(ref_num_word))[::-1]:\n","      if ref_num_word[index_ref] in pred_synonymm:\n","        matching_word_by_word.append(tuple([pred_num_word[index_pred][0], ref_num_word[index_ref][0]]))\n","        ref_num_word.pop(index_ref)\n","        pred_num_word.pop(index_pred)\n","        break\n","  return matching_word_by_word, ref_num_word, pred_num_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CP5Bn4JsWpd","executionInfo":{"status":"ok","timestamp":1691991302266,"user_tz":-210,"elapsed":39,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"98710952-8b20-49a7-fbd7-85e0ff779c48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["synonymm_matching_word_by_word , ref_num_word , pred_num_word = _synonymm_matching_word_by_word(ref_num_word, pred_num_word)"],"metadata":{"id":"9Qp3AKNDs7zt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ref_num_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L--3GMTDtYru","executionInfo":{"status":"ok","timestamp":1691991303519,"user_tz":-210,"elapsed":36,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"1d52b81c-c1aa-40aa-ad93-40a1919ad6fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["pred_num_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZPY1uwKtbCP","executionInfo":{"status":"ok","timestamp":1691991303520,"user_tz":-210,"elapsed":34,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"a4f75320-d14c-4c8d-8647-182f7188a573"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(2, 'wa')]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["synonymm_matching_word_by_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWzyiDMFtcU3","executionInfo":{"status":"ok","timestamp":1691991303520,"user_tz":-210,"elapsed":30,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"c01076fd-8ae6-4db2-8c20-04e5809a8dc8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["<div dir=rtl>\n","حالا تمام اشتراک را باهم جمع کرده\n","</div>\n"],"metadata":{"id":"O5AMCGBkuuiT"}},{"cell_type":"code","source":["all_marches = sorted(matching_word_by_word + stemmer_matching_word_by_word + synonymm_matching_word_by_word, key=lambda element : element[0])\n","all_marches"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UwXChr9wtdfT","executionInfo":{"status":"ok","timestamp":1691991303520,"user_tz":-210,"elapsed":27,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"a3d3fd76-45a2-4ffd-8ea7-61fe3075f372"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 0), (1, 1), (3, 2), (4, 3), (5, 4), (6, 5)]"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["<div dir=rtl>\n","نوبت محاصبه امتیاز نهایی است\n","</div>\n","\n","```\n","\t\tref_lenght = len(ref.split())\n","\t\tpred_lenght = len(pred.split())\n","\t\tmatches_lenght = len(all_marches)\n","\t\tchunk = self._chunks(all_marches)\n","\t\ttry:\n","\t\t\tprecision = matches_lenght / pred_lenght\n","\t\t\trecall = matches_lenght / ref_lenght\n","\t\t\tfscore = (precision * recall * 10) / ((9 * precision) +  recall)\n","\t\t\tchunk_count = self._chunks(all_marches)\n","\t\t\tfrag_frac = chunk_count / matches_lenght\n","\t\texcept ZeroDivisionError:\n","\t\t\treturn 0\n","\n","\t\tpenalty = 0.5 * (frag_frac ** 3)\n","\t\treturn fscore * (1 - penalty)\n","```\n","\n"],"metadata":{"id":"HkthpQnIvLYF"}},{"cell_type":"markdown","source":["<div dir=rtl>\n","اگر شمار تکه ها صفر باشد امتیاز ضربدر یک شده ولی اگر همه کلمات مشترک تکه باشند امتیاز نهایی ضربدر ۰٫۵ میشود</div>\n","\n","\n","\n","\n","```\n","\tdef _chunks(self, matches):\n","\t\tindex = 0\n","\t\tchunk = 1\n","\n","\t\twhile index < len(matches) - 1:\n","\t\t\tif (matches[index + 1][0] == matches[index][0] + 1) and (matches[index + 1][1] == matches[index][1] + 1):\n","\t\t\t\tindex += 1\n","\t\t\t\tcontinue\n","\n","\t\t\tchunk += 1\n","\t\t\tindex += 1\n","\t\treturn chunk\n","```\n","\n"],"metadata":{"id":"YXaj-hxEvZuW"}},{"cell_type":"code","source":["def _chunks(matches):\n","  index = 0\n","  chunk = 0\n","\n","  while index < len(matches) - 1:\n","    if (matches[index + 1][0] == matches[index][0] + 1) and (matches[index + 1][1] == matches[index][1] + 1):\n","      index += 1\n","      continue\n","\n","    chunk += 1\n","    index += 1\n","  return chunk"],"metadata":{"id":"uRI8rGGCvKzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_chunks(all_marches)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOmwsENLwSlD","executionInfo":{"status":"ok","timestamp":1691991303521,"user_tz":-210,"elapsed":25,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"c7a007de-1713-47ab-85c5-f5f0d222cd3f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["ref_lenght = len(ref.split())\n","pred_lenght = len(pred.split())\n","matches_lenght = len(all_marches)\n","chunk = _chunks(all_marches)\n","try:\n","  precision = matches_lenght / pred_lenght\n","  recall = matches_lenght / ref_lenght\n","  fscore = (precision * recall * 10) / ((9 * precision) +  recall)\n","  chunk_count = _chunks(all_marches)\n","  frag_frac = chunk_count / matches_lenght\n","except ZeroDivisionError:\n","  print(0)\n","\n","penalty = 0.5 * (frag_frac ** 3)\n","print(fscore * (1 - penalty))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5G_7rCHywW0t","executionInfo":{"status":"ok","timestamp":1691991303521,"user_tz":-210,"elapsed":23,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"20386301-aab0-4921-d1d4-b81ede16e97f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.981329690346084\n"]}]},{"cell_type":"markdown","source":["#<div dir=rtl>\n","<h1> <b>کد</b></h1>\n","</div>"],"metadata":{"id":"ndxrJkXLzyON"}},{"cell_type":"code","source":["from nltk.corpus import WordNetCorpusReader, wordnet\n","from nltk.stem.api import StemmerI\n","from nltk.stem.porter import PorterStemmer\n","\n","\n","class meteor:\n","\tdef __init__(self):\n","\t\tself.stemmer = PorterStemmer()\n","\n","\tdef meteor_score(self, refs, pred):\n","\t\treturn max([self._metor_single_refs_pred(ref, pred) for ref in refs])\n","\n","\tdef _metor_single_refs_pred(self, ref, pred):\n","\t\tref_num_word = self._create_num(ref)\n","\t\tpred_num_word = self._create_num(pred)\n","\n","\t\t#matching_word by word\n","\t\tmatching_word_by_word , ref_num_word , pred_num_word = self._matching_word_by_word(ref_num_word, pred_num_word)\n","\n","\t\t#stemmer matching word by word\n","\t\tstemmer_matching_word_by_word , ref_num_word , pred_num_word = self._stemmer_matching_word_by_word(ref_num_word, pred_num_word)\n","\n","\t\t#synonymm atching word by word\n","\t\tsynonymm_matching_word_by_word , ref_num_word , pred_num_word = self._synonymm_matching_word_by_word(ref_num_word, pred_num_word)\n","\n","\n","\t\tall_marches = sorted(matching_word_by_word + stemmer_matching_word_by_word + synonymm_matching_word_by_word, key=lambda element : element[0])\n","\n","\t\tref_lenght = len(ref.split())\n","\t\tpred_lenght = len(pred.split())\n","\t\tmatches_lenght = len(all_marches)\n","\t\tchunk = self._chunks(all_marches)\n","\t\ttry:\n","\t\t\tprecision = matches_lenght / pred_lenght\n","\t\t\trecall = matches_lenght / ref_lenght\n","\t\t\tfscore = (precision * recall * 10) / ((9 * precision) +  recall)\n","\t\t\tchunk_count = self._chunks(all_marches)\n","\t\t\tfrag_frac = chunk_count / matches_lenght\n","\t\texcept ZeroDivisionError:\n","\t\t\treturn 0\n","\n","\t\tpenalty = 0.5 * (frag_frac ** 3)\n","\t\treturn fscore * (1 - penalty)\n","\n","\tdef _matching_word_by_word(self, ref_num_word, pred_num_word):\n","\t\tmatching_word_by_word = list()\n","\t\tfor index_pred in range(0 , len(pred_num_word))[::-1]:\n","\t\t\tfor index_ref in range(0, len(ref_num_word))[::-1]:\n","\t\t\t\tif pred_num_word[index_pred][1] == ref_num_word[index_ref][1]:\n","\t\t\t\t\tmatching_word_by_word.append(tuple([pred_num_word[index_pred][0], ref_num_word[index_ref][0]]))\n","\t\t\t\t\tref_num_word.pop(index_ref)\n","\t\t\t\t\tpred_num_word.pop(index_pred)\n","\t\t\t\t\tbreak\n","\t\treturn matching_word_by_word , ref_num_word, pred_num_word\n","\n","\tdef _stemmer_matching_word_by_word(self, ref_num_word, pred_num_word):\n","\t\tref_num_word = [tuple([element[0], self.stemmer.stem(element[1])]) for element in ref_num_word]\n","\t\tpred_num_word = [tuple([element[0], self.stemmer.stem(element[1])]) for element in pred_num_word]\n","\t\treturn self._matching_word_by_word(ref_num_word, pred_num_word)\n","\n","\tdef _synonymm_matching_word_by_word(self, ref_num_word, pred_num_word):\n","\t\tmatching_word_by_word = []\n","\t\tfor index_pred in range(0, len(pred_num_word))[::-1]:\n","\t\t\tword_synonymms= wordnet.synsets(pred_num_word[index_pred][1])\n","\t\t\tpred_synonymm = [pred_num_word[index_pred][1]]\n","\n","\t\t\tfor synonymm in word_synonymms:\n","\t\t\t\tfor lemma in synonymm.lemmas():\n","\t\t\t\t\tif lemma.name().find(\"_\") < 0:\n","\t\t\t\t\t\tpred_synonymm.append(lemma.name())\n","\n","\t\t\tpred_synonymm = set(pred_synonymm)\n","\n","\t\t\tfor index_ref in range(0, len(ref_num_word))[::-1]:\n","\t\t\t\tif ref_num_word[index_ref] in pred_synonymm:\n","\t\t\t\t\tmatching_word_by_word.append(tuple([pred_num_word[index_pred][0], ref_num_word[index_ref][0]]))\n","\t\t\t\t\tref_num_word.pop(index_ref)\n","\t\t\t\t\tpred_num_word.pop(index_pred)\n","\t\t\t\t\tbreak\n","\t\treturn matching_word_by_word, ref_num_word, pred_num_word\n","\n","\tdef _chunks(self, matches):\n","\t\tindex = 0\n","\t\tchunk = 0\n","\n","\t\twhile index < len(matches) - 1:\n","\t\t\tif (matches[index + 1][0] == matches[index][0] + 1) and (matches[index + 1][1] == matches[index][1] + 1):\n","\t\t\t\tindex += 1\n","\t\t\t\tcontinue\n","\n","\t\t\tchunk += 1\n","\t\t\tindex += 1\n","\t\treturn chunk\n","\n","\tdef _create_num(self, text):\n","\t\ttext = text.lower()\n","\t\twords = text.split()\n","\t\tnum_words = [tuple([index, words[index]]) for index in range(len(words))]\n","\t\treturn num_words\n","\n","\n","\n"],"metadata":{"id":"KTc2j0DKz6a6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##<div dir=rtl>\n","<h3> <b>تست کد با مثال</b></h3>\n","</div>"],"metadata":{"id":"ym0jb2bjz-TZ"}},{"cell_type":"code","source":["model = meteor()"],"metadata":{"id":"YhJvik7Pz9D9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##<div dir=rtl>\n","<h4> <b>جملات یکسان</b></h4>\n","</div>"],"metadata":{"id":"ymoj35Bk0dW3"}},{"cell_type":"code","source":["ref = \"this is a blue ball\"\n","pred = \"this is a blue ball\"\n","model.meteor_score([ref], pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TQtbRY90XRl","executionInfo":{"status":"ok","timestamp":1691991303522,"user_tz":-210,"elapsed":21,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"1c92b98e-f730-4e3e-c1f4-f1e8f94daecd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["ref = \"this is a blue ball\"\n","pred = \"this is  a bluue ball\"\n","model.meteor_score([ref], pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQqwYZzYip2l","executionInfo":{"status":"ok","timestamp":1691991403064,"user_tz":-210,"elapsed":4,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"9701932e-fcc8-4733-f77f-3fa73088a620"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7937500000000002"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["##<div dir=rtl>\n","<h4> <b>جملات کاملا متفاوت </b></h4>\n","</div>"],"metadata":{"id":"RBqudT72054k"}},{"cell_type":"code","source":["ref = \"this is a blue ball\"\n","pred = \"i love python and java\"\n","model.meteor_score([ref], pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gY5LNrbn05MU","executionInfo":{"status":"ok","timestamp":1691991303522,"user_tz":-210,"elapsed":18,"user":{"displayName":"Alireza Parvaresh","userId":"13077413390910589098"}},"outputId":"e3a7d6de-a7be-4d3a-8fd6-5c6ac3ce22f4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["#<div dir=rtl>\n","<h1> <b>نتیجه گیری</b></h1>\n","</div>"],"metadata":{"id":"dUsymggJ1gZ5"}},{"cell_type":"markdown","source":["<div dir=rtl>\n","\n","عدد خروجی این متریک بین صفر و یک است\n","\n","* یک به معنای تطابق صد در صدی با جمله مرجع\n","\n","* صفر به معنای عدم تطابق صد در صدی با جمله مرجع\n","\n","</div>"],"metadata":{"id":"4y9O4F331hHL"}},{"cell_type":"markdown","source":["#<div dir=rtl>\n","<h1> <b>منابع</b></h1>\n","</div>\n","\n","* [ref - 1](https://www.cs.cmu.edu/~alavie/METEOR/pdf/Lavie-Agarwal-2007-METEOR.pdf)\n","\n","* [ref - 2](https://www.mdpi.com/2227-7390/11/4/1006)"],"metadata":{"id":"-1aD2MaD2pKj"}}]}